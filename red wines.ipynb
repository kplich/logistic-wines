{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  good  \n",
      "0      9.4        5     0  \n",
      "1      9.8        5     0  \n",
      "2      9.8        5     0  \n",
      "3      9.8        6     1  \n",
      "4      9.4        5     0  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.95892834e-01, -5.56834399e-01,  4.62334643e-01, ...,\n",
       "         2.06482073e-01, -1.15961429e+00, -9.48173158e-01],\n",
       "       [-1.40052778e+00, -1.33715344e+00, -1.03370076e-01, ...,\n",
       "         1.40757934e-01, -6.89067171e-01, -9.40831096e-02],\n",
       "       [-9.98982797e-01,  4.46432942e-01, -1.33763492e+00, ...,\n",
       "         2.50682696e+00,  4.28482234e-01,  9.57146790e-02],\n",
       "       ...,\n",
       "       [-2.38021275e-02,  1.39396321e+00, -8.74785603e-01, ...,\n",
       "         1.12662003e+00, -7.47885561e-01, -3.78779792e-01],\n",
       "       [-1.95892834e-01,  1.67264858e+00, -5.14672920e-04, ...,\n",
       "        -1.22138624e-01, -1.04197751e+00, -5.68577581e-01],\n",
       "       [-1.05634637e+00,  5.36345983e-04, -1.08049641e+00, ...,\n",
       "         4.69378632e-01,  1.01666613e+00, -9.40831096e-02]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv(\"data/winequality-red.csv\")\n",
    "validation_indexes = pd.read_csv(\"data/validation indexes.csv\")\n",
    "\n",
    "# Introduce new binary variable \"good\" equal 1 for wines with quality greater than or equal 7\n",
    "dataset = dataset.assign(good = dataset[\"quality\"] >= 6)\n",
    "dataset[\"good\"] = dataset[\"good\"].astype(int)\n",
    "print(dataset.head())\n",
    "\n",
    "# Drop all rows that belong to the validation set\n",
    "dataset.drop(labels=validation_indexes[\"index\"], inplace=True)\n",
    "\n",
    "# Extract independent variables - all eleven columns\n",
    "X = dataset.iloc[:, :11] # it's useful not to drop column names - makes outputs clearer\n",
    "\n",
    "# Extract the dependent \"good\" variable\n",
    "y = dataset.iloc[:, 12]\n",
    "\n",
    "# Split the model into test and validation?\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)\n",
    "\n",
    "# Scale the data to a standard distribution\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X)\n",
    "scaler.transform(X_train)\n",
    "scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the classifier on a scikit Logistic Regression model with cross-validation.\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 87  31]\n",
      " [ 29 113]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.74      0.74       118\n",
      "          1       0.78      0.80      0.79       142\n",
      "\n",
      "avg / total       0.77      0.77      0.77       260\n",
      "\n",
      "Coefficients:\n",
      "\n",
      "[[-0.02798375 -2.9722091  -0.32619856 -0.00300579 -1.52907568  0.02285837\n",
      "  -0.01781595 -1.00410248 -1.51402804  1.46650502  0.84532336]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the classifier on a scikit Logistic Regression model with cross-validation.\\n\")\n",
    "\n",
    "# Training the classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion matrix:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Coefficients:\\n\")\n",
    "print(classifier.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the classifier on a statsmodels Logit model\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.508449\n",
      "         Iterations 6\n",
      "Confusion matrix:\n",
      "[[180  64]\n",
      " [ 77 199]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.74      0.72       244\n",
      "          1       0.76      0.72      0.74       276\n",
      "\n",
      "avg / total       0.73      0.73      0.73       520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try new model\n",
    "import statsmodels.discrete.discrete_model as sm\n",
    "\n",
    "print(\"Training the classifier on a statsmodels Logit model\")\n",
    "logit = sm.Logit(y_train, X_train)\n",
    "result = logit.fit()\n",
    "\n",
    "y_pred = [(int)(x >= 0.5) for x in result.predict(X_test).values]\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.56834399e-01, -1.72052416e-01, -2.73482704e-01, ...,\n",
       "         4.36082586e-01, -1.15961429e+00, -9.48173158e-01],\n",
       "       [-1.33715344e+00,  7.94975668e+00, -4.39956008e-01, ...,\n",
       "         2.26848685e-01, -6.89067171e-01, -9.40831096e-02],\n",
       "       [ 4.46432942e-01, -4.64730222e-01, -1.69436888e-01, ...,\n",
       "         3.60972981e-01,  4.28482234e-01,  9.57146790e-02],\n",
       "       ...,\n",
       "       [ 1.39396321e+00,  4.74559374e-02, -1.48627725e-01, ...,\n",
       "         8.11630613e-01, -7.47885561e-01, -3.78779792e-01],\n",
       "       [ 1.67264858e+00, -3.91560770e-01, -1.69436888e-01, ...,\n",
       "        -1.43334370e-01, -1.04197751e+00, -5.68577581e-01],\n",
       "       [ 5.36345983e-04, -3.91560770e-01, -5.23192661e-01, ...,\n",
       "        -1.01782478e+00,  1.01666613e+00, -9.40831096e-02]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fixed acidity, citric acid content, free sulfur dioxide, and pH have high p values and don't help with predictions.\n",
    "#Let's try dropping these columns.\n",
    "\n",
    "columns=[\"fixed acidity\", \"citric acid\", \"free sulfur dioxide\", \"pH\"]\n",
    "\n",
    "simple_dataset = dataset.copy()\n",
    "simple_dataset.drop(columns=columns, inplace=True)\n",
    "\n",
    "X_new = simple_dataset.copy().drop(columns = [\"quality\", \"good\"])\n",
    "y_new = simple_dataset.good.copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size = 0.4, random_state=0)\n",
    "\n",
    "# Scale the data to a standard distribution\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_new)\n",
    "scaler.transform(X_train)\n",
    "scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a scikit model on simplified data.\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 87  31]\n",
      " [ 30 112]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.74      0.74       118\n",
      "          1       0.78      0.79      0.79       142\n",
      "\n",
      "avg / total       0.77      0.77      0.77       260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train scikit model using new data\n",
    "print(\"Training a scikit model on simplified data.\\n\")\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion matrix:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the classifier on a statsmodels model with simplified data.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.523542\n",
      "         Iterations 6\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 87  31]\n",
      " [ 33 109]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.74      0.73       118\n",
      "          1       0.78      0.77      0.77       142\n",
      "\n",
      "avg / total       0.75      0.75      0.75       260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try new model\n",
    "print(\"Training the classifier on a statsmodels model with simplified data.\")\n",
    "logit = sm.Logit(y_train, X_train)\n",
    "result = logit.fit()\n",
    "\n",
    "y_pred = [(int)(x >= 0.5) for x in result.predict(X_test).values ]\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion matrix:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on training set:\n",
      "{'C': 1, 'class_weight': None, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.474 (+/-0.001) for {'C': 1e-05, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.509 (+/-0.050) for {'C': 1e-05, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.559 (+/-0.026) for {'C': 1e-05, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.603 (+/-0.019) for {'C': 1e-05, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.474 (+/-0.001) for {'C': 1e-05, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.491 (+/-0.050) for {'C': 1e-05, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.516 (+/-0.035) for {'C': 1e-05, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.537 (+/-0.047) for {'C': 1e-05, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.474 (+/-0.001) for {'C': 0.0001, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.526 (+/-0.001) for {'C': 0.0001, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.625 (+/-0.006) for {'C': 0.0001, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.626 (+/-0.008) for {'C': 0.0001, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.474 (+/-0.001) for {'C': 0.0001, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.508 (+/-0.050) for {'C': 0.0001, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.621 (+/-0.020) for {'C': 0.0001, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.621 (+/-0.020) for {'C': 0.0001, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.474 (+/-0.001) for {'C': 0.001, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.568 (+/-0.066) for {'C': 0.001, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.627 (+/-0.017) for {'C': 0.001, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.627 (+/-0.017) for {'C': 0.001, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.474 (+/-0.001) for {'C': 0.001, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.515 (+/-0.089) for {'C': 0.001, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.621 (+/-0.015) for {'C': 0.001, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.621 (+/-0.015) for {'C': 0.001, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.628 (+/-0.014) for {'C': 0.01, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.628 (+/-0.014) for {'C': 0.01, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.645 (+/-0.022) for {'C': 0.01, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.633 (+/-0.030) for {'C': 0.01, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.622 (+/-0.013) for {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.622 (+/-0.013) for {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.635 (+/-0.003) for {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.628 (+/-0.041) for {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.712 (+/-0.038) for {'C': 0.1, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.636 (+/-0.034) for {'C': 0.1, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.718 (+/-0.047) for {'C': 0.1, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.633 (+/-0.034) for {'C': 0.1, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.725 (+/-0.047) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.634 (+/-0.029) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.726 (+/-0.047) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.625 (+/-0.026) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.736 (+/-0.047) for {'C': 1, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.639 (+/-0.040) for {'C': 1, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.739 (+/-0.037) for {'C': 1, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.634 (+/-0.036) for {'C': 1, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.738 (+/-0.044) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.630 (+/-0.027) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.738 (+/-0.037) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.624 (+/-0.023) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.735 (+/-0.032) for {'C': 10, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.635 (+/-0.039) for {'C': 10, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.741 (+/-0.039) for {'C': 10, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.634 (+/-0.036) for {'C': 10, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.738 (+/-0.054) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.632 (+/-0.028) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.736 (+/-0.051) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.625 (+/-0.023) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.731 (+/-0.040) for {'C': 100, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.635 (+/-0.039) for {'C': 100, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.732 (+/-0.037) for {'C': 100, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.634 (+/-0.036) for {'C': 100, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.736 (+/-0.054) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.632 (+/-0.028) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.736 (+/-0.054) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.625 (+/-0.023) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.731 (+/-0.040) for {'C': 1000, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.635 (+/-0.039) for {'C': 1000, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.731 (+/-0.040) for {'C': 1000, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.634 (+/-0.036) for {'C': 1000, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.736 (+/-0.054) for {'C': 1000, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.632 (+/-0.028) for {'C': 1000, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.736 (+/-0.054) for {'C': 1000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.624 (+/-0.020) for {'C': 1000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.731 (+/-0.037) for {'C': 10000, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.636 (+/-0.036) for {'C': 10000, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.731 (+/-0.037) for {'C': 10000, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.634 (+/-0.036) for {'C': 10000, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.736 (+/-0.054) for {'C': 10000, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.632 (+/-0.028) for {'C': 10000, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.736 (+/-0.054) for {'C': 10000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.624 (+/-0.020) for {'C': 10000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.731 (+/-0.037) for {'C': 100000, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.635 (+/-0.039) for {'C': 100000, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.731 (+/-0.037) for {'C': 100000, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.634 (+/-0.036) for {'C': 100000, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.736 (+/-0.054) for {'C': 100000, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.632 (+/-0.028) for {'C': 100000, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.736 (+/-0.054) for {'C': 100000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.624 (+/-0.020) for {'C': 100000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.732 (+/-0.040) for {'C': 1000000, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.636 (+/-0.036) for {'C': 1000000, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.731 (+/-0.037) for {'C': 1000000, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.634 (+/-0.036) for {'C': 1000000, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.736 (+/-0.054) for {'C': 1000000, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.632 (+/-0.028) for {'C': 1000000, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.736 (+/-0.054) for {'C': 1000000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.625 (+/-0.023) for {'C': 1000000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.615 (+/-0.017) for {'C': 1e-05, 'class_weight': None, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.615 (+/-0.017) for {'C': 1e-05, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.606 (+/-0.035) for {'C': 1e-05, 'class_weight': None, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.606 (+/-0.020) for {'C': 1e-05, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.606 (+/-0.020) for {'C': 1e-05, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.565 (+/-0.065) for {'C': 1e-05, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.628 (+/-0.017) for {'C': 0.0001, 'class_weight': None, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.628 (+/-0.017) for {'C': 0.0001, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.626 (+/-0.008) for {'C': 0.0001, 'class_weight': None, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.614 (+/-0.020) for {'C': 0.0001, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.614 (+/-0.020) for {'C': 0.0001, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.620 (+/-0.015) for {'C': 0.0001, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.638 (+/-0.038) for {'C': 0.001, 'class_weight': None, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.638 (+/-0.038) for {'C': 0.001, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.626 (+/-0.017) for {'C': 0.001, 'class_weight': None, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.647 (+/-0.014) for {'C': 0.001, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.647 (+/-0.014) for {'C': 0.001, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.621 (+/-0.015) for {'C': 0.001, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.705 (+/-0.076) for {'C': 0.01, 'class_weight': None, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.706 (+/-0.078) for {'C': 0.01, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.639 (+/-0.035) for {'C': 0.01, 'class_weight': None, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.714 (+/-0.078) for {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.714 (+/-0.078) for {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.629 (+/-0.020) for {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.736 (+/-0.059) for {'C': 0.1, 'class_weight': None, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.741 (+/-0.062) for {'C': 0.1, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.639 (+/-0.040) for {'C': 0.1, 'class_weight': None, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.726 (+/-0.070) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.725 (+/-0.081) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.630 (+/-0.027) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.747 (+/-0.042) for {'C': 1, 'class_weight': None, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.738 (+/-0.037) for {'C': 1, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.636 (+/-0.036) for {'C': 1, 'class_weight': None, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.740 (+/-0.058) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.739 (+/-0.039) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.632 (+/-0.028) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.740 (+/-0.038) for {'C': 10, 'class_weight': None, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.734 (+/-0.043) for {'C': 10, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.637 (+/-0.034) for {'C': 10, 'class_weight': None, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.740 (+/-0.054) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.739 (+/-0.037) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.632 (+/-0.028) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.735 (+/-0.035) for {'C': 100, 'class_weight': None, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.734 (+/-0.044) for {'C': 100, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.636 (+/-0.036) for {'C': 100, 'class_weight': None, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.738 (+/-0.049) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.735 (+/-0.030) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.632 (+/-0.028) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.732 (+/-0.040) for {'C': 1000, 'class_weight': None, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.735 (+/-0.042) for {'C': 1000, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.637 (+/-0.034) for {'C': 1000, 'class_weight': None, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.739 (+/-0.047) for {'C': 1000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.737 (+/-0.030) for {'C': 1000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.632 (+/-0.028) for {'C': 1000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.732 (+/-0.040) for {'C': 10000, 'class_weight': None, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.735 (+/-0.042) for {'C': 10000, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.636 (+/-0.036) for {'C': 10000, 'class_weight': None, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.738 (+/-0.045) for {'C': 10000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.737 (+/-0.033) for {'C': 10000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.632 (+/-0.028) for {'C': 10000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.732 (+/-0.040) for {'C': 100000, 'class_weight': None, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.739 (+/-0.035) for {'C': 100000, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.637 (+/-0.034) for {'C': 100000, 'class_weight': None, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.740 (+/-0.040) for {'C': 100000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.736 (+/-0.033) for {'C': 100000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.632 (+/-0.028) for {'C': 100000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.732 (+/-0.040) for {'C': 1000000, 'class_weight': None, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.733 (+/-0.047) for {'C': 1000000, 'class_weight': None, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.636 (+/-0.036) for {'C': 1000000, 'class_weight': None, 'penalty': 'l2', 'solver': 'sag'}\n",
      "0.735 (+/-0.052) for {'C': 1000000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.734 (+/-0.032) for {'C': 1000000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.632 (+/-0.028) for {'C': 1000000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'sag'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "[[ 88  30]\n",
      " [ 32 110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.75      0.74       118\n",
      "          1       0.79      0.77      0.78       142\n",
      "\n",
      "avg / total       0.76      0.76      0.76       260\n",
      "\n",
      "0.7615384615384615\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Let's try grid search on the original dataset!\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scores = ['accuracy']\n",
    "\n",
    "tuned_parameters = [{'C': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000],\n",
    "                     'class_weight': [None, 'balanced'],\n",
    "                     'penalty': ['l1', 'l2'],\n",
    "                     'solver': ['liblinear', 'saga']},\n",
    "                    {'C': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000],\n",
    "                     'class_weight': [None, 'balanced'],\n",
    "                     'penalty': ['l2'],\n",
    "                     'solver': ['newton-cg', 'lbfgs', 'sag']}\n",
    "                    ]\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    \n",
    "    clf = GridSearchCV(LogisticRegression(), tuned_parameters, cv=3, scoring=score)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best parameters set found on training set:\")\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(clf.score(X_test, y_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 87  31]\n",
      " [ 29 113]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.74      0.74       118\n",
      "          1       0.78      0.80      0.79       142\n",
      "\n",
      "avg / total       0.77      0.77      0.77       260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's get sure about the best classifier here.\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 88  30]\n",
      " [ 32 110]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.75      0.74       118\n",
      "          1       0.79      0.77      0.78       142\n",
      "\n",
      "avg / total       0.76      0.76      0.76       260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(solver='newton-cg')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
