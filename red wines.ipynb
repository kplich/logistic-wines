{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  good  \n",
      "0      9.4        5     0  \n",
      "1      9.8        5     0  \n",
      "2      9.8        5     0  \n",
      "3      9.8        6     0  \n",
      "4      9.4        5     0  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: good, dtype: int32"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv(\"data/winequality-red.csv\")\n",
    "\n",
    "# Introduce new binary variable \"good\" equal 1 for wines with quality greater than or equal 7\n",
    "dataset = dataset.assign(good = dataset[\"quality\"] >= 7)\n",
    "dataset[\"good\"] = dataset[\"good\"].astype(int)\n",
    "print(dataset.head())\n",
    "\n",
    "# Extract independent variables - all eleven columns\n",
    "X = dataset.iloc[:, :11] # it's useful not to drop column names - makes outputs clearer\n",
    "\n",
    "# Extract the dependent \"good\" variable\n",
    "y = dataset.iloc[:, 12]\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programy\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.4250439 , -0.32301294,  0.81659759, ..., -0.91431164,\n",
       "         0.60105502,  0.35389538],\n",
       "       [-0.1261883 ,  1.63225386, -1.39147228, ...,  0.3167512 ,\n",
       "        -0.75624575, -0.77251161],\n",
       "       [ 0.44834214, -1.32857872,  0.30309297, ..., -0.33117661,\n",
       "         1.07315963,  1.19870062],\n",
       "       ...,\n",
       "       [ 0.44834214, -1.04925489,  0.76524713, ..., -0.84951886,\n",
       "        -0.6382196 ,  0.91709887],\n",
       "       [ 0.44834214,  1.32499765, -1.18607043, ..., -0.13679827,\n",
       "        -0.69723268, -0.67864436],\n",
       "       [-0.06873526, -1.16098443,  0.76524713, ..., -0.26638383,\n",
       "        -0.6382196 ,  1.76190411]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the model into test and validation?\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)\n",
    "\n",
    "# Scale the data to a standard distribution\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X)\n",
    "scaler.transform(X_train)\n",
    "scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[283   7]\n",
      " [ 20  10]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.98      0.95       290\n",
      "          1       0.59      0.33      0.43        30\n",
      "\n",
      "avg / total       0.90      0.92      0.90       320\n",
      "\n",
      "0.915625\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.284355\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>good</td>       <th>  No. Observations:  </th>  <td>  1279</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  1272</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 05 Dec 2018</td> <th>  Pseudo R-squ.:     </th>  <td>0.3166</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>22:15:36</td>     <th>  Log-Likelihood:    </th> <td> -363.69</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -532.16</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>9.818e-70</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>volatile acidity</th>     <td>   -4.3982</td> <td>    0.667</td> <td>   -6.591</td> <td> 0.000</td> <td>   -5.706</td> <td>   -3.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>residual sugar</th>       <td>    0.1743</td> <td>    0.063</td> <td>    2.778</td> <td> 0.005</td> <td>    0.051</td> <td>    0.297</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chlorides</th>            <td>   -8.0333</td> <td>    3.364</td> <td>   -2.388</td> <td> 0.017</td> <td>  -14.626</td> <td>   -1.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total sulfur dioxide</th> <td>   -0.0126</td> <td>    0.003</td> <td>   -3.600</td> <td> 0.000</td> <td>   -0.019</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>              <td>  -11.6291</td> <td>    1.235</td> <td>   -9.413</td> <td> 0.000</td> <td>  -14.051</td> <td>   -9.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sulphates</th>            <td>    3.3506</td> <td>    0.539</td> <td>    6.214</td> <td> 0.000</td> <td>    2.294</td> <td>    4.407</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alcohol</th>              <td>    0.9467</td> <td>    0.092</td> <td>   10.340</td> <td> 0.000</td> <td>    0.767</td> <td>    1.126</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                   good   No. Observations:                 1279\n",
       "Model:                          Logit   Df Residuals:                     1272\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Wed, 05 Dec 2018   Pseudo R-squ.:                  0.3166\n",
       "Time:                        22:15:36   Log-Likelihood:                -363.69\n",
       "converged:                       True   LL-Null:                       -532.16\n",
       "                                        LLR p-value:                 9.818e-70\n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "volatile acidity        -4.3982      0.667     -6.591      0.000      -5.706      -3.090\n",
       "residual sugar           0.1743      0.063      2.778      0.005       0.051       0.297\n",
       "chlorides               -8.0333      3.364     -2.388      0.017     -14.626      -1.441\n",
       "total sulfur dioxide    -0.0126      0.003     -3.600      0.000      -0.019      -0.006\n",
       "density                -11.6291      1.235     -9.413      0.000     -14.051      -9.208\n",
       "sulphates                3.3506      0.539      6.214      0.000       2.294       4.407\n",
       "alcohol                  0.9467      0.092     10.340      0.000       0.767       1.126\n",
       "========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "#print(y_pred)\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Print more results\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = [\"0\", \"1\"]\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(classifier.score(X_test, y_test))\n",
    "\n",
    "# Try new model\n",
    "import statsmodels.discrete.discrete_model as sm\n",
    "logit = sm.Logit(y_train, X_train)\n",
    "result = logit.fit()\n",
    "result.summary()\n",
    "\n",
    "# what does it do????\n",
    "# Try cross-validation?? wtf\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# scores = cross_val_score(classifier, X, y, cv=10)\n",
    "# print(scores)\n",
    "# print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.32301294, -0.31132282,  1.7753969 , ...,  0.77027994,\n",
       "         0.60105502,  0.35389538],\n",
       "       [ 1.63225386,  1.10763304,  0.16011403, ...,  0.9504846 ,\n",
       "        -0.75624575, -0.77251161],\n",
       "       [-1.32857872, -0.34679672, -0.52000507, ..., -0.84096169,\n",
       "         1.07315963,  1.19870062],\n",
       "       ...,\n",
       "       [-1.04925489, -0.5241662 , -0.62627368, ..., -1.49817867,\n",
       "        -0.6382196 ,  0.91709887],\n",
       "       [ 1.32499765, -0.66606179, -0.20119924, ...,  0.6642772 ,\n",
       "        -0.69723268, -0.67864436],\n",
       "       [-1.16098443, -0.16942723,  0.2238752 , ..., -0.89396306,\n",
       "        -0.6382196 ,  1.76190411]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fixed acidity, citric acid content, free sulfur dioxide, and pH have high p values and don't help with predictions.\n",
    "#Let's try dropping these columns.\n",
    "\n",
    "simple_dataset = dataset.copy()\n",
    "simple_dataset.drop(columns=[\"fixed acidity\", \"citric acid\", \"free sulfur dioxide\", \"pH\"], inplace=True)\n",
    "\n",
    "X_new = simple_dataset.copy().drop(columns = [\"quality\", \"good\"])\n",
    "y_new = simple_dataset.good.copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size = 0.2, random_state=0)\n",
    "\n",
    "# Scale the data to a standard distribution\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X_new)\n",
    "scaler.transform(X_train)\n",
    "scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[283   7]\n",
      " [ 20  10]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.98      0.95       290\n",
      "          1       0.59      0.33      0.43        30\n",
      "\n",
      "avg / total       0.90      0.92      0.90       320\n",
      "\n",
      "0.915625\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.284355\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>good</td>       <th>  No. Observations:  </th>  <td>  1279</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  1272</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 05 Dec 2018</td> <th>  Pseudo R-squ.:     </th>  <td>0.3166</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>22:24:49</td>     <th>  Log-Likelihood:    </th> <td> -363.69</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -532.16</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>9.818e-70</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>volatile acidity</th>     <td>   -4.3982</td> <td>    0.667</td> <td>   -6.591</td> <td> 0.000</td> <td>   -5.706</td> <td>   -3.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>residual sugar</th>       <td>    0.1743</td> <td>    0.063</td> <td>    2.778</td> <td> 0.005</td> <td>    0.051</td> <td>    0.297</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chlorides</th>            <td>   -8.0333</td> <td>    3.364</td> <td>   -2.388</td> <td> 0.017</td> <td>  -14.626</td> <td>   -1.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total sulfur dioxide</th> <td>   -0.0126</td> <td>    0.003</td> <td>   -3.600</td> <td> 0.000</td> <td>   -0.019</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>              <td>  -11.6291</td> <td>    1.235</td> <td>   -9.413</td> <td> 0.000</td> <td>  -14.051</td> <td>   -9.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sulphates</th>            <td>    3.3506</td> <td>    0.539</td> <td>    6.214</td> <td> 0.000</td> <td>    2.294</td> <td>    4.407</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alcohol</th>              <td>    0.9467</td> <td>    0.092</td> <td>   10.340</td> <td> 0.000</td> <td>    0.767</td> <td>    1.126</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                   good   No. Observations:                 1279\n",
       "Model:                          Logit   Df Residuals:                     1272\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Wed, 05 Dec 2018   Pseudo R-squ.:                  0.3166\n",
       "Time:                        22:24:49   Log-Likelihood:                -363.69\n",
       "converged:                       True   LL-Null:                       -532.16\n",
       "                                        LLR p-value:                 9.818e-70\n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "volatile acidity        -4.3982      0.667     -6.591      0.000      -5.706      -3.090\n",
       "residual sugar           0.1743      0.063      2.778      0.005       0.051       0.297\n",
       "chlorides               -8.0333      3.364     -2.388      0.017     -14.626      -1.441\n",
       "total sulfur dioxide    -0.0126      0.003     -3.600      0.000      -0.019      -0.006\n",
       "density                -11.6291      1.235     -9.413      0.000     -14.051      -9.208\n",
       "sulphates                3.3506      0.539      6.214      0.000       2.294       4.407\n",
       "alcohol                  0.9467      0.092     10.340      0.000       0.767       1.126\n",
       "========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train scikit model using new data\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Print confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(classifier.score(X_test, y_test))\n",
    "\n",
    "# Train statsmodels on new data\n",
    "logit = sm.Logit(y_train, X_train)\n",
    "result = logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on training set:\n",
      "\n",
      "{'C': 10, 'class_weight': None, 'tol': 0.001}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.854 (+/-0.006) for {'C': 0.01, 'class_weight': None, 'tol': 0.001}\n",
      "0.854 (+/-0.006) for {'C': 0.01, 'class_weight': None, 'tol': 0.0001}\n",
      "0.854 (+/-0.006) for {'C': 0.01, 'class_weight': None, 'tol': 1e-05}\n",
      "0.557 (+/-0.096) for {'C': 0.01, 'class_weight': 'balanced', 'tol': 0.001}\n",
      "0.557 (+/-0.096) for {'C': 0.01, 'class_weight': 'balanced', 'tol': 0.0001}\n",
      "0.557 (+/-0.096) for {'C': 0.01, 'class_weight': 'balanced', 'tol': 1e-05}\n",
      "0.854 (+/-0.006) for {'C': 0.1, 'class_weight': None, 'tol': 0.001}\n",
      "0.854 (+/-0.006) for {'C': 0.1, 'class_weight': None, 'tol': 0.0001}\n",
      "0.854 (+/-0.006) for {'C': 0.1, 'class_weight': None, 'tol': 1e-05}\n",
      "0.756 (+/-0.042) for {'C': 0.1, 'class_weight': 'balanced', 'tol': 0.001}\n",
      "0.756 (+/-0.042) for {'C': 0.1, 'class_weight': 'balanced', 'tol': 0.0001}\n",
      "0.756 (+/-0.042) for {'C': 0.1, 'class_weight': 'balanced', 'tol': 1e-05}\n",
      "0.868 (+/-0.055) for {'C': 1, 'class_weight': None, 'tol': 0.001}\n",
      "0.868 (+/-0.055) for {'C': 1, 'class_weight': None, 'tol': 0.0001}\n",
      "0.868 (+/-0.055) for {'C': 1, 'class_weight': None, 'tol': 1e-05}\n",
      "0.785 (+/-0.054) for {'C': 1, 'class_weight': 'balanced', 'tol': 0.001}\n",
      "0.787 (+/-0.054) for {'C': 1, 'class_weight': 'balanced', 'tol': 0.0001}\n",
      "0.787 (+/-0.054) for {'C': 1, 'class_weight': 'balanced', 'tol': 1e-05}\n",
      "0.873 (+/-0.053) for {'C': 10, 'class_weight': None, 'tol': 0.001}\n",
      "0.873 (+/-0.052) for {'C': 10, 'class_weight': None, 'tol': 0.0001}\n",
      "0.873 (+/-0.052) for {'C': 10, 'class_weight': None, 'tol': 1e-05}\n",
      "0.783 (+/-0.061) for {'C': 10, 'class_weight': 'balanced', 'tol': 0.001}\n",
      "0.786 (+/-0.063) for {'C': 10, 'class_weight': 'balanced', 'tol': 0.0001}\n",
      "0.786 (+/-0.063) for {'C': 10, 'class_weight': 'balanced', 'tol': 1e-05}\n",
      "0.872 (+/-0.053) for {'C': 100, 'class_weight': None, 'tol': 0.001}\n",
      "0.871 (+/-0.054) for {'C': 100, 'class_weight': None, 'tol': 0.0001}\n",
      "0.872 (+/-0.052) for {'C': 100, 'class_weight': None, 'tol': 1e-05}\n",
      "0.787 (+/-0.064) for {'C': 100, 'class_weight': 'balanced', 'tol': 0.001}\n",
      "0.788 (+/-0.064) for {'C': 100, 'class_weight': 'balanced', 'tol': 0.0001}\n",
      "0.788 (+/-0.064) for {'C': 100, 'class_weight': 'balanced', 'tol': 1e-05}\n",
      "0.872 (+/-0.053) for {'C': 1000, 'class_weight': None, 'tol': 0.001}\n",
      "0.869 (+/-0.056) for {'C': 1000, 'class_weight': None, 'tol': 0.0001}\n",
      "0.870 (+/-0.054) for {'C': 1000, 'class_weight': None, 'tol': 1e-05}\n",
      "0.787 (+/-0.064) for {'C': 1000, 'class_weight': 'balanced', 'tol': 0.001}\n",
      "0.788 (+/-0.063) for {'C': 1000, 'class_weight': 'balanced', 'tol': 0.0001}\n",
      "0.788 (+/-0.063) for {'C': 1000, 'class_weight': 'balanced', 'tol': 1e-05}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the training set.\n",
      "The scores are computed on the test set.\n",
      "\n",
      "[[276  14]\n",
      " [ 19  11]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.95      0.94       290\n",
      "          1       0.44      0.37      0.40        30\n",
      "\n",
      "avg / total       0.89      0.90      0.89       320\n",
      "\n",
      "0.896875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Let's try grid search on the original dataset!\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scores = ['accuracy']\n",
    "\n",
    "tuned_parameters = [{'tol': [1e-3, 1e-4, 1e-5],\n",
    "                      'C': [0.01, 0.1, 1, 10, 100, 1000],\n",
    "                      'class_weight': [None, 'balanced']}\n",
    "                    ]\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    \n",
    "    clf = GridSearchCV(LogisticRegression(), tuned_parameters, cv=10, scoring=score)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best parameters set found on training set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the training set.\")\n",
    "    print(\"The scores are computed on the test set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(clf.score(X_test, y_test))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
