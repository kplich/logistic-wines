{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  good  \n",
      "0      9.4        5     0  \n",
      "1      9.8        5     0  \n",
      "2      9.8        5     0  \n",
      "3      9.8        6     1  \n",
      "4      9.4        5     0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programy\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.95892834e-01, -5.56834399e-01,  4.62334643e-01, ...,\n",
       "         2.06482073e-01, -1.15961429e+00, -9.48173158e-01],\n",
       "       [-1.40052778e+00, -1.33715344e+00, -1.03370076e-01, ...,\n",
       "         1.40757934e-01, -6.89067171e-01, -9.40831096e-02],\n",
       "       [-9.98982797e-01,  4.46432942e-01, -1.33763492e+00, ...,\n",
       "         2.50682696e+00,  4.28482234e-01,  9.57146790e-02],\n",
       "       ...,\n",
       "       [-2.38021275e-02,  1.39396321e+00, -8.74785603e-01, ...,\n",
       "         1.12662003e+00, -7.47885561e-01, -3.78779792e-01],\n",
       "       [-1.95892834e-01,  1.67264858e+00, -5.14672920e-04, ...,\n",
       "        -1.22138624e-01, -1.04197751e+00, -5.68577581e-01],\n",
       "       [-1.05634637e+00,  5.36345983e-04, -1.08049641e+00, ...,\n",
       "         4.69378632e-01,  1.01666613e+00, -9.40831096e-02]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv(\"data/winequality-red.csv\")\n",
    "validation_indexes = pd.read_csv(\"data/validation indexes.csv\")\n",
    "\n",
    "# Introduce new binary variable \"good\" equal 1 for wines with quality greater than or equal 7\n",
    "dataset = dataset.assign(good = dataset[\"quality\"] >= 6)\n",
    "dataset[\"good\"] = dataset[\"good\"].astype(int)\n",
    "print(dataset.head())\n",
    "\n",
    "dataset.drop(labels=validation_indexes[\"index\"], inplace=True)\n",
    "\n",
    "# Extract independent variables - all eleven columns\n",
    "X = dataset.iloc[:, :11] # it's useful not to drop column names - makes outputs clearer\n",
    "\n",
    "# Extract the dependent \"good\" variable\n",
    "y = dataset.iloc[:, 12]\n",
    "\n",
    "# y.head()\n",
    "\n",
    "# Split the model into test and validation?\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)\n",
    "\n",
    "# Scale the data to a standard distribution\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X)\n",
    "scaler.transform(X_train)\n",
    "scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the classifier on a scikit Logistic Regression model\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 87  31]\n",
      " [ 29 113]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.74      0.74       118\n",
      "          1       0.78      0.80      0.79       142\n",
      "\n",
      "avg / total       0.77      0.77      0.77       260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "print(\"Training the classifier on a scikit Logistic Regression model\\n\")\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = classifier.predict(X_test)\n",
    "#print(y_pred)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion matrix:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the classifier on a statsmodels Logit model\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.520112\n",
      "         Iterations 6\n",
      "[0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1]\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 87  31]\n",
      " [ 31 111]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.74      0.74       118\n",
      "          1       0.78      0.78      0.78       142\n",
      "\n",
      "avg / total       0.76      0.76      0.76       260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try new model\n",
    "import statsmodels.discrete.discrete_model as sm\n",
    "\n",
    "print(\"Training the classifier on a statsmodels Logit model\")\n",
    "logit = sm.Logit(y_train, X_train)\n",
    "result = logit.fit()\n",
    "\n",
    "y_pred = [(int)(x >= 0.5) for x in result.predict(X_test).values]\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.56834399e-01, -1.72052416e-01, -2.73482704e-01, ...,\n",
       "         4.36082586e-01, -1.15961429e+00, -9.48173158e-01],\n",
       "       [-1.33715344e+00,  7.94975668e+00, -4.39956008e-01, ...,\n",
       "         2.26848685e-01, -6.89067171e-01, -9.40831096e-02],\n",
       "       [ 4.46432942e-01, -4.64730222e-01, -1.69436888e-01, ...,\n",
       "         3.60972981e-01,  4.28482234e-01,  9.57146790e-02],\n",
       "       ...,\n",
       "       [ 1.39396321e+00,  4.74559374e-02, -1.48627725e-01, ...,\n",
       "         8.11630613e-01, -7.47885561e-01, -3.78779792e-01],\n",
       "       [ 1.67264858e+00, -3.91560770e-01, -1.69436888e-01, ...,\n",
       "        -1.43334370e-01, -1.04197751e+00, -5.68577581e-01],\n",
       "       [ 5.36345983e-04, -3.91560770e-01, -5.23192661e-01, ...,\n",
       "        -1.01782478e+00,  1.01666613e+00, -9.40831096e-02]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fixed acidity, citric acid content, free sulfur dioxide, and pH have high p values and don't help with predictions.\n",
    "#Let's try dropping these columns.\n",
    "\n",
    "columns=[\"fixed acidity\", \"citric acid\", \"free sulfur dioxide\", \"pH\"]\n",
    "\n",
    "simple_dataset = dataset.copy()\n",
    "simple_dataset.drop(columns=columns, inplace=True)\n",
    "\n",
    "X_new = simple_dataset.copy().drop(columns = [\"quality\", \"good\"])\n",
    "y_new = simple_dataset.good.copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size = 0.2, random_state=0)\n",
    "\n",
    "# Scale the data to a standard distribution\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_new)\n",
    "scaler.transform(X_train)\n",
    "scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a scikit model on simplified data.\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 87  31]\n",
      " [ 30 112]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.74      0.74       118\n",
      "          1       0.78      0.79      0.79       142\n",
      "\n",
      "avg / total       0.77      0.77      0.77       260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train scikit model using new data\n",
    "print(\"Training a scikit model on simplified data.\\n\")\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion matrix:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the classifier on a statsmodels model with simplified data.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.523542\n",
      "         Iterations 6\n",
      "Confusion matrix:\n",
      "\n",
      "[[ 87  31]\n",
      " [ 33 109]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.74      0.73       118\n",
      "          1       0.78      0.77      0.77       142\n",
      "\n",
      "avg / total       0.75      0.75      0.75       260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try new model\n",
    "print(\"Training the classifier on a statsmodels model with simplified data.\")\n",
    "logit = sm.Logit(y_train, X_train)\n",
    "result = logit.fit()\n",
    "\n",
    "y_pred = [(int)(x >= 0.5) for x in result.predict(X_test).values ]\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion matrix:\\n\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on training set:\n",
      "\n",
      "{'C': 100, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.628 (+/-0.068) for {'C': 0.1, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001}\n",
      "0.628 (+/-0.068) for {'C': 0.1, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001}\n",
      "0.628 (+/-0.068) for {'C': 0.1, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05}\n",
      "0.710 (+/-0.087) for {'C': 0.1, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.710 (+/-0.087) for {'C': 0.1, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.710 (+/-0.087) for {'C': 0.1, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.627 (+/-0.067) for {'C': 0.1, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001}\n",
      "0.627 (+/-0.067) for {'C': 0.1, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001}\n",
      "0.627 (+/-0.067) for {'C': 0.1, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05}\n",
      "0.707 (+/-0.097) for {'C': 0.1, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.706 (+/-0.101) for {'C': 0.1, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.707 (+/-0.097) for {'C': 0.1, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.629 (+/-0.048) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001}\n",
      "0.629 (+/-0.048) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001}\n",
      "0.629 (+/-0.048) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05}\n",
      "0.704 (+/-0.083) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.705 (+/-0.083) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.705 (+/-0.083) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.626 (+/-0.049) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001}\n",
      "0.627 (+/-0.050) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001}\n",
      "0.626 (+/-0.049) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05}\n",
      "0.705 (+/-0.080) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.705 (+/-0.080) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.705 (+/-0.078) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.628 (+/-0.072) for {'C': 1, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001}\n",
      "0.628 (+/-0.072) for {'C': 1, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001}\n",
      "0.628 (+/-0.072) for {'C': 1, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05}\n",
      "0.742 (+/-0.087) for {'C': 1, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.742 (+/-0.087) for {'C': 1, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.742 (+/-0.087) for {'C': 1, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.627 (+/-0.067) for {'C': 1, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001}\n",
      "0.627 (+/-0.067) for {'C': 1, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001}\n",
      "0.627 (+/-0.067) for {'C': 1, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05}\n",
      "0.741 (+/-0.078) for {'C': 1, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.741 (+/-0.078) for {'C': 1, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.741 (+/-0.078) for {'C': 1, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.629 (+/-0.050) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001}\n",
      "0.629 (+/-0.050) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001}\n",
      "0.628 (+/-0.052) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05}\n",
      "0.741 (+/-0.101) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.742 (+/-0.100) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.742 (+/-0.100) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.627 (+/-0.050) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001}\n",
      "0.626 (+/-0.049) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001}\n",
      "0.626 (+/-0.049) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05}\n",
      "0.738 (+/-0.088) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.737 (+/-0.089) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.737 (+/-0.089) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.628 (+/-0.072) for {'C': 10, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001}\n",
      "0.627 (+/-0.070) for {'C': 10, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001}\n",
      "0.627 (+/-0.070) for {'C': 10, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05}\n",
      "0.744 (+/-0.096) for {'C': 10, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.744 (+/-0.099) for {'C': 10, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.744 (+/-0.099) for {'C': 10, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.627 (+/-0.067) for {'C': 10, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001}\n",
      "0.627 (+/-0.067) for {'C': 10, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001}\n",
      "0.627 (+/-0.067) for {'C': 10, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05}\n",
      "0.740 (+/-0.100) for {'C': 10, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.742 (+/-0.100) for {'C': 10, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.742 (+/-0.100) for {'C': 10, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.628 (+/-0.050) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001}\n",
      "0.628 (+/-0.053) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001}\n",
      "0.628 (+/-0.053) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05}\n",
      "0.740 (+/-0.108) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.739 (+/-0.108) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.739 (+/-0.108) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.626 (+/-0.049) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001}\n",
      "0.627 (+/-0.050) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001}\n",
      "0.627 (+/-0.050) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05}\n",
      "0.742 (+/-0.098) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.739 (+/-0.102) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.738 (+/-0.105) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.627 (+/-0.070) for {'C': 100, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001}\n",
      "0.628 (+/-0.072) for {'C': 100, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001}\n",
      "0.627 (+/-0.070) for {'C': 100, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05}\n",
      "0.744 (+/-0.099) for {'C': 100, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.745 (+/-0.099) for {'C': 100, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.745 (+/-0.099) for {'C': 100, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.627 (+/-0.067) for {'C': 100, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001}\n",
      "0.627 (+/-0.067) for {'C': 100, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001}\n",
      "0.627 (+/-0.067) for {'C': 100, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05}\n",
      "0.741 (+/-0.103) for {'C': 100, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.743 (+/-0.105) for {'C': 100, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.743 (+/-0.105) for {'C': 100, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.628 (+/-0.056) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001}\n",
      "0.628 (+/-0.056) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001}\n",
      "0.628 (+/-0.056) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05}\n",
      "0.738 (+/-0.107) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.738 (+/-0.107) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.738 (+/-0.107) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.627 (+/-0.050) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001}\n",
      "0.627 (+/-0.050) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001}\n",
      "0.626 (+/-0.049) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05}\n",
      "0.737 (+/-0.105) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.737 (+/-0.106) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.738 (+/-0.107) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.627 (+/-0.070) for {'C': 1000, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001}\n",
      "0.627 (+/-0.070) for {'C': 1000, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001}\n",
      "0.627 (+/-0.070) for {'C': 1000, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05}\n",
      "0.744 (+/-0.099) for {'C': 1000, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.745 (+/-0.099) for {'C': 1000, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.745 (+/-0.099) for {'C': 1000, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.627 (+/-0.067) for {'C': 1000, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001}\n",
      "0.627 (+/-0.067) for {'C': 1000, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001}\n",
      "0.627 (+/-0.067) for {'C': 1000, 'class_weight': None, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05}\n",
      "0.742 (+/-0.104) for {'C': 1000, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.745 (+/-0.099) for {'C': 1000, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.745 (+/-0.099) for {'C': 1000, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.628 (+/-0.056) for {'C': 1000, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001}\n",
      "0.628 (+/-0.056) for {'C': 1000, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001}\n",
      "0.628 (+/-0.056) for {'C': 1000, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05}\n",
      "0.738 (+/-0.107) for {'C': 1000, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.738 (+/-0.107) for {'C': 1000, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.738 (+/-0.107) for {'C': 1000, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.627 (+/-0.050) for {'C': 1000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001}\n",
      "0.626 (+/-0.049) for {'C': 1000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001}\n",
      "0.626 (+/-0.049) for {'C': 1000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05}\n",
      "0.737 (+/-0.105) for {'C': 1000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.738 (+/-0.107) for {'C': 1000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.738 (+/-0.107) for {'C': 1000, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the training set.\n",
      "The scores are computed on the test set.\n",
      "\n",
      "[[ 87  31]\n",
      " [ 33 109]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.74      0.73       118\n",
      "          1       0.78      0.77      0.77       142\n",
      "\n",
      "avg / total       0.75      0.75      0.75       260\n",
      "\n",
      "0.7538461538461538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Let's try grid search on the original dataset!\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scores = ['accuracy']\n",
    "\n",
    "tuned_parameters = [{'tol': [1e-3, 1e-4, 1e-5],\n",
    "                      'C': [0.1, 1, 10, 100, 1000],\n",
    "                      'class_weight': [None, 'balanced'],\n",
    "                      'penalty': ['l1', 'l2'],\n",
    "                      'solver': ['saga', 'liblinear']}\n",
    "                    ]\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    \n",
    "    clf = GridSearchCV(LogisticRegression(), tuned_parameters, cv=10, scoring=score)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best parameters set found on training set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the training set.\")\n",
    "    print(\"The scores are computed on the test set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(clf.score(X_test, y_test))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
